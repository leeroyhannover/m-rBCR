{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67009765-2034-4084-a420-1ccae2e3713d",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Test model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b106430e-bca6-451c-8b53-d059323d9d05",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Test Unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4240f8e0-d6fd-4d94-9797-192473bb49fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.Unet import *\n",
    "\n",
    "model = simple_unet_model(256, 256, 1)\n",
    "model.summary()\n",
    "print('input shape:', model.input_shape)\n",
    "print('output shape:', model.output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2549d0b9-1185-4ca1-b080-653a1bb9693c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dea00da0-aeac-48de-a5fe-53cb934834bc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Test DDPM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "342017df-f48f-4ed6-8786-dcf4c4985faf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/li52/.conda/envs/LM/lib/python3.7/site-packages/requests/__init__.py:104: RequestsDependencyWarning: urllib3 (1.26.9) or chardet (5.1.0)/charset_normalizer (2.0.4) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n",
      "/home/li52/.conda/envs/LM/lib/python3.7/site-packages/tensorflow_addons/utils/ensure_tf_install.py:67: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.7.0 and strictly below 2.10.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.6.2 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  UserWarning,\n"
     ]
    }
   ],
   "source": [
    "from util.ddpm_utils import *\n",
    "from models.ddpm import *\n",
    "\n",
    "lr = 1e-4\n",
    "opt_m = tf.keras.optimizers.Adam(lr)\n",
    "patch_size = 128\n",
    "timesteps = 2000\n",
    "timesteps_test = 200\n",
    "train_steps = int(1.2e6)\n",
    "ds_sample = int(1e4)\n",
    "print_freq = int(1e3)\n",
    "lr_change_ts = int(4e5)\n",
    "img_channels = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9920af0b-fff8-4343-9a0f-bac4485b9bd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-21 14:30:33.884076: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-21 14:30:34.512698: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30987 MB memory:  -> device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:8a:00.0, compute capability: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 8, 8, 1024)\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 128, 128, 1) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               [(None, 128, 128, 1) 0           input_1[0][0]                    \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 128, 128, 1) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model (Functional)              (None, 128, 128, 1)  23988353    lambda_1[0][0]                   \n",
      "                                                                 input_2[0][0]                    \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.subtract (TFOpLambda)   (None, 128, 128, 1)  0           model[0][0]                      \n",
      "                                                                 lambda_1[0][1]                   \n",
      "==================================================================================================\n",
      "Total params: 23,988,353\n",
      "Trainable params: 23,988,353\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "[(None, 128, 128, 1), (None, 128, 128, 1), (None, 1)] (None, 128, 128, 1)\n",
      "[(None, 128, 128, 1), (None, 128, 128, 1), (None, 1)] (None, 128, 128, 1)\n"
     ]
    }
   ],
   "source": [
    "gamma_vec_t, alpha_vec = variance_schedule(timesteps, schedule_type='cos')\n",
    "p_model, t_model = train_model((patch_size, patch_size, img_channels), img_channels)\n",
    "t_model.compile(loss='mse', optimizer=opt_m)  # 用于sinus embedding的\n",
    "# print(p_model.summary())  # unet\n",
    "# print(t_model.summary())  # 简单的fc\n",
    "print(p_model.input_shape, p_model.output_shape)\n",
    "print(t_model.input_shape, t_model.output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9b03c9-68de-4e45-ab83-0878675d0257",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac4da77-1048-41b0-bb29-9c6db158e4f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a623581-ba30-4692-aae1-22ee32c61929",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a944a5-424a-4afd-a991-26d9d2a563f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c81b2ab7-08af-482b-aa1c-b029d50a8faf",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Test s-rBCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a857b2d0-8230-4e6f-b09c-92a477b24ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.s_rBCR import *\n",
    "\n",
    "# Example usage:\n",
    "forward_model_RDN = BCR_RDN(input_shape=(128, 128, 1), alpha=32, p=0.2, nb=3, K=12, L=12, L0=12, RDN=5)\n",
    "inverse_model_RDN = inverse_RDN(alpha1=32, alpha2=4, w1=5, w2=9, Ncnn1=6, Ncnn2=5, RDN=5)\n",
    "\n",
    "input_shape=(128, 128, 1)\n",
    "inputs = Input(shape=input_shape)\n",
    "x = inputs\n",
    "\n",
    "y = forward_model_RDN(x)\n",
    "z = inverse_model_RDN(y)\n",
    "model = Model(inputs=inputs, outputs=z)\n",
    "\n",
    "print(model.input_shape, model.output_shape)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad21258-0546-4682-8164-003273e8e46b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Test m-rBCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84fe75d2-e68d-4396-88a3-9202721b516a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/li52/.conda/envs/LM/lib/python3.7/site-packages/requests/__init__.py:104: RequestsDependencyWarning: urllib3 (1.26.9) or chardet (5.1.0)/charset_normalizer (2.0.4) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n",
      "2023-11-21 14:05:11.441747: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-21 14:05:12.071350: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30987 MB memory:  -> device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:8a:00.0, compute capability: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(None, 128, 128, 1), (None, 64, 64, 1), (None, 32, 32, 1)] [(None, 128, 128, 1), (None, 64, 64, 1), (None, 32, 32, 1)]\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "x0_input (InputLayer)           [(None, 128, 128, 1) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "x2_input (InputLayer)           [(None, 64, 64, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "x4_input (InputLayer)           [(None, 32, 32, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model (Functional)              [(None, 128, 128, 1) 46531       x0_input[0][0]                   \n",
      "                                                                 x2_input[0][0]                   \n",
      "                                                                 x4_input[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "model_1 (Functional)            [(None, 128, 128, 1) 190099      model[0][0]                      \n",
      "                                                                 model[0][1]                      \n",
      "                                                                 model[0][2]                      \n",
      "==================================================================================================\n",
      "Total params: 236,630\n",
      "Trainable params: 236,630\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from models.m_rBCR import *\n",
    "\n",
    "# Create the full model\n",
    "Nrho = 128\n",
    "Ntheta = 128\n",
    "input_shape = (Nrho, Ntheta, 1)\n",
    "\n",
    "x0 = Input(shape=input_shape, name='x0_input')\n",
    "x2 = Input(shape=(input_shape[0] // 2, input_shape[1] // 2, input_shape[2]), name='x2_input')\n",
    "x4 = Input(shape=(input_shape[0] // 4, input_shape[1] // 4, input_shape[2]), name='x4_input')\n",
    "\n",
    "# initialize the model\n",
    "\n",
    "forward_model_RDN = BCR_RDN_mimo(input_shape=(128, 128, 1), alpha=32, p=0.2, nb=3, K=12, L=12, L0=12, RDN=7) \n",
    "inverse_model_RDN = inverse_RDN_mimo(input_shape=(128, 128, 1), alpha1=32, alpha2=4, w1=5, w2=9, Ncnn1=6, Ncnn2=5, RDN=7)\n",
    "\n",
    "[y0, y2, y4] = forward_model_RDN([x0, x2, x4])\n",
    "[z0, z2, z4] = inverse_model_RDN([y0, y2, y4])\n",
    "\n",
    "model = Model(inputs=[x0, x2, x4], outputs=[z0, z2, z4])\n",
    "print(model.input_shape, model.output_shape) # [(None, 128, 128, 1), (None, 64, 64, 1), (None, 32, 32, 1)] \n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b06a33e-daaa-46fa-87a1-f3db8ca5835a",
   "metadata": {},
   "source": [
    "# Test the train func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95cf2ed4-2965-4991-8820-aa9fecc46830",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/li52/.conda/envs/LM/lib/python3.7/site-packages/requests/__init__.py:104: RequestsDependencyWarning: urllib3 (1.26.9) or chardet (5.1.0)/charset_normalizer (2.0.4) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n"
     ]
    }
   ],
   "source": [
    "from train import *\n",
    "train_m_rBCR()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d45f5b2-352f-4778-9e46-788d96d22958",
   "metadata": {},
   "source": [
    "# Test the test func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9407d5a6-0f69-429c-b852-39c2d489b7e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9d29e6-8672-4d60-98c5-023291f035d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775e933d-d2c3-4204-aefb-c06c5b3e9187",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbcad6d9-a578-43d9-a90c-44987f01ffa1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CONDA (LM)",
   "language": "python",
   "name": "n2v-conda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
