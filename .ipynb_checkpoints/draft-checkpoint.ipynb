{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51ffd57c-e350-47e5-9338-72f032d9e156",
   "metadata": {},
   "source": [
    "# Test on m-rBCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a0f0f75-6e4a-4f00-b083-f06094420bf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/li52/.conda/envs/LM/lib/python3.7/site-packages/requests/__init__.py:104: RequestsDependencyWarning: urllib3 (1.26.9) or chardet (5.1.0)/charset_normalizer (2.0.4) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n"
     ]
    }
   ],
   "source": [
    "# test on different dataset\n",
    "import os \n",
    "import numpy as np\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import random\n",
    "from natsort import natsorted\n",
    "\n",
    "from util.utils import *\n",
    "from models.m_rBCR import *\n",
    "from util.loss_func import *\n",
    "from util.metrics import *\n",
    "from util.data import *\n",
    "\n",
    "def multi_input(w_img, o_img):\n",
    "    \n",
    "    w_0, o_0 = w_img, o_img\n",
    "    w_2, o_2 = w_0[:, ::2, ::2, :], o_0[:, ::2, ::2, :]\n",
    "    w_4, o_4 = w_0[:, ::4, ::4, :], o_0[:, ::4, ::4, :]\n",
    "    \n",
    "    return [w_0, w_2, w_4], [o_0, o_2, o_4]\n",
    "\n",
    "def save_3_levels(image_list, output_path, domain, kind):\n",
    "    \n",
    "    for i in range(len(image_list)):\n",
    "        image = image_list[i]\n",
    "        plt.figure(figsize=(1.28, 1.28), dpi=300)  # Set figsize and dpi to match the 128x128 size\n",
    "        plt.imshow(image, cmap='gray')\n",
    "        plt.axis('off')\n",
    "        svg_filename = os.path.join(output_path, f\"{str(kind)}_{i:03d}_{str(domain)}.svg\")\n",
    "        plt.savefig(svg_filename, format='svg', bbox_inches='tight', pad_inches=0)\n",
    "    print('finish save')\n",
    "\n",
    "\n",
    "def test(path = './weights/m-rBCR/'):\n",
    "    eval_model = model_m_rBCR()\n",
    "    eval_model.compile(optimizer='adam', loss=loss_function_mimo, metrics=[metrics_func_mimo]) # 这里是损失函数\n",
    "\n",
    "    print(eval_model.input_shape, eval_model.output_shape) # [(None, 128, 128, 1), (None, 64, 64, 1), (None, 32, 32, 1)] \n",
    "    print(eval_model.summary())\n",
    "\n",
    "    # reload the check point\n",
    "    checkpoint = tf.train.Checkpoint(model=eval_model)\n",
    "    checkpoint_manager = tf.train.CheckpointManager(checkpoint, path, max_to_keep=5)\n",
    "\n",
    "    # Specify the checkpoint you want to restore for testing\n",
    "    checkpoint_to_restore = path + '/ckpt-24'\n",
    "    # Restore the model's weights\n",
    "    status = checkpoint.restore(checkpoint_to_restore)\n",
    "    status.assert_consumed()\n",
    "    \n",
    "    test_dir = './data/test/'\n",
    "    test_list = natsorted(os.listdir(test_dir))  \n",
    "    \n",
    "    test_raw = np.load(test_dir + test_list[0])  # select testset [imn, bio, storm, w_c]\n",
    "    w_test_img, o_test_img = test_raw['w'], test_raw['o']\n",
    "    test_w_list, test_o_list = multi_input(w_test_img, o_test_img)\n",
    "    \n",
    "    pred_test_list = eval_model.predict(test_w_list)\n",
    "    \n",
    "    # save a rnadom fig under path\n",
    "    # NUM = random.randint(0, pred_test_list[0].shape[0]-1)\n",
    "    NUM = 24\n",
    "    fig_path = './results/m_rBCR/'\n",
    "    pred_list_level= pred_test_list[0][NUM], pred_test_list[1][NUM], pred_test_list[2][NUM]\n",
    "    test_w_list_level = test_w_list[0][NUM], test_w_list[1][NUM], test_w_list[2][NUM]\n",
    "    save_3_levels(pred_list_level, fig_path, 'bio', 'pre')\n",
    "    save_3_levels(test_w_list_level, fig_path, 'bio', 'w')\n",
    "    print('test saved at:', fig_path)\n",
    "    \n",
    "    psnr_value, ssim_value, rmse = metrics(pred_test_list[0], test_o_list[0])\n",
    "    print('test performance:', psnr_value.round(2), ssim_value.round(2), rmse.round(2))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37365622-80aa-4d5b-a88d-b0fbd80e8d45",
   "metadata": {},
   "source": [
    "# Test on s-rBCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e13784f-0ef5-4ac6-83ce-fc751bb6aea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/li52/.conda/envs/LM/lib/python3.7/site-packages/requests/__init__.py:104: RequestsDependencyWarning: urllib3 (1.26.9) or chardet (5.1.0)/charset_normalizer (2.0.4) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n"
     ]
    }
   ],
   "source": [
    "# test on different dataset\n",
    "import os \n",
    "import numpy as np\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import random\n",
    "from natsort import natsorted\n",
    "from keras.models import load_model\n",
    "\n",
    "from util.utils import *\n",
    "from models.s_rBCR import *\n",
    "from util.loss_func import *\n",
    "from util.metrics import *\n",
    "from util.data import *\n",
    "\n",
    "def save_svg(image_stack, domain, kind, path):\n",
    "    # Define the path where you want to save the SVG files\n",
    "    output_path = path\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "    # Loop through the image stack and save each element as an SVG file\n",
    "    for i in range(image_stack.shape[0]):\n",
    "        image = image_stack[i, :, :, 0]\n",
    "\n",
    "        plt.figure(figsize=(1.28, 1.28), dpi=300)  # Set figsize and dpi to match the 128x128 size\n",
    "        plt.imshow(image, cmap='gray')\n",
    "        plt.axis('off')\n",
    "        svg_filename = os.path.join(output_path, f\"{str(kind)}_{i:03d}_{str(domain)}.svg\")\n",
    "        plt.savefig(svg_filename, format='svg', bbox_inches='tight', pad_inches=0)\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "def test(path = './weights/s-rBCR/'):\n",
    "    eval_model = model_s_rBCR()\n",
    "    eval_model.compile(optimizer='adam', loss=loss_function_mimo, metrics=[metrics_func_mimo]) # 这里是损失函数\n",
    "\n",
    "    print(eval_model.input_shape, eval_model.output_shape) # [(None, 128, 128, 1), (None, 64, 64, 1), (None, 32, 32, 1)] \n",
    "    print(eval_model.summary())\n",
    "\n",
    "    eval_model = load_model(path+'single_bcr_best.h5', compile=False)\n",
    "    \n",
    "    test_dir = './data/test/'\n",
    "    test_list = natsorted(os.listdir(test_dir))  \n",
    "    \n",
    "    test_raw = np.load(test_dir + test_list[0])  # select testset [imn, bio, storm, w_c]\n",
    "    w_test_img, o_test_img = test_raw['w'], test_raw['gt']\n",
    "    \n",
    "    pred_test_img = eval_model.predict(w_test_img)\n",
    "    \n",
    "    \n",
    "    # save a rnadom fig under path\n",
    "    # NUM = random.randint(0, pred_test_list[0].shape[0]-1)\n",
    "    NUM = 24\n",
    "    fig_path = './results/s_rBCR/'\n",
    "    save_svg(np.expand_dims(pred_test_img[NUM],axis=0), 'single_rBCR', 'pre', fig_path)\n",
    "    save_svg(np.expand_dims(o_test_img[NUM],axis=0), 'single_rBCR', 'o', fig_path)\n",
    "    save_svg(np.expand_dims(w_test_img[NUM],axis=0), 'single_rBCR', 'w', fig_path)\n",
    "    print('test saved at:', fig_path)\n",
    "    \n",
    "    psnr_value, ssim_value, rmse = metrics(pred_test_img, o_test_img)\n",
    "    print('test performance:', psnr_value.round(2), ssim_value.round(2), rmse.round(2))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7322eca-ef96-49a4-8c5e-b6f534794027",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-23 11:13:46.567156: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-23 11:13:52.553744: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30987 MB memory:  -> device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:89:00.0, compute capability: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 128, 128, 1) (None, 128, 128, 1)\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 128, 128, 1)]     0         \n",
      "_________________________________________________________________\n",
      "model (Functional)           (None, 128, 128, 128)     15904     \n",
      "_________________________________________________________________\n",
      "model_1 (Functional)         (None, 128, 128, 1)       70945     \n",
      "=================================================================\n",
      "Total params: 86,849\n",
      "Trainable params: 86,849\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-23 11:13:58.892885: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2023-11-23 11:14:08.578368: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8201\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test saved at: ./results/s_rBCR/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/li52/code/LM/m-rBCR/util/metrics.py:14: FutureWarning: `multichannel` is a deprecated argument name for `structural_similarity`. It will be removed in version 1.0. Please use `channel_axis` instead.\n",
      "  ssim_value = ssim(IMG1, IMG2, multichannel=True)\n",
      "/home/li52/.conda/envs/LM/lib/python3.7/site-packages/skimage/_shared/utils.py:348: UserWarning: Inputs have mismatched dtype.  Setting data_range based on im1.dtype.\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test performance: 20.67 0.73 0.09\n"
     ]
    }
   ],
   "source": [
    "test()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abdc12a2-6c07-4503-bda6-a574be955f3f",
   "metadata": {},
   "source": [
    "# Unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc29a0d2-5f0f-4bf4-a3f8-56943dd70d5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/li52/.conda/envs/LM/lib/python3.7/site-packages/requests/__init__.py:104: RequestsDependencyWarning: urllib3 (1.26.9) or chardet (5.1.0)/charset_normalizer (2.0.4) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n",
      "/home/li52/.conda/envs/LM/lib/python3.7/site-packages/tensorflow_addons/utils/ensure_tf_install.py:67: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.7.0 and strictly below 2.10.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.6.2 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  UserWarning,\n"
     ]
    }
   ],
   "source": [
    "# test on different dataset\n",
    "import os \n",
    "import numpy as np\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import random\n",
    "from natsort import natsorted\n",
    "from keras.models import load_model\n",
    "from keras_contrib.layers.normalization.instancenormalization import InstanceNormalization\n",
    "\n",
    "from util.utils import *\n",
    "from models.Unet import *\n",
    "from util.loss_func import *\n",
    "from util.metrics import *\n",
    "from util.data import *\n",
    "\n",
    "def save_svg(image_stack, domain, kind, path):\n",
    "    # Define the path where you want to save the SVG files\n",
    "    output_path = path\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "    # Loop through the image stack and save each element as an SVG file\n",
    "    for i in range(image_stack.shape[0]):\n",
    "        image = image_stack[i, :, :, 0]\n",
    "\n",
    "        plt.figure(figsize=(1.28, 1.28), dpi=300)  # Set figsize and dpi to match the 128x128 size\n",
    "        plt.imshow(image, cmap='gray')\n",
    "        plt.axis('off')\n",
    "        svg_filename = os.path.join(output_path, f\"{str(kind)}_{i:03d}_{str(domain)}.svg\")\n",
    "        plt.savefig(svg_filename, format='svg', bbox_inches='tight', pad_inches=0)\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "def test(path = './weights/Unet/'):\n",
    "    \n",
    "    eval_model = load_model(path+'Unet_best.hdf5', compile=False, custom_objects={'InstanceNormalization':InstanceNormalization})\n",
    "    \n",
    "    test_dir = './data/test/'\n",
    "    test_list = natsorted(os.listdir(test_dir))  \n",
    "    \n",
    "    test_raw = np.load(test_dir + test_list[0])  # select testset [imn, bio, storm, w_c]\n",
    "    w_test_img, o_test_img = test_raw['w'], test_raw['gt']\n",
    "    \n",
    "    pred_test_img = eval_model.predict(w_test_img)\n",
    "    \n",
    "    # save a rnadom fig under path\n",
    "    # NUM = random.randint(0, pred_test_list[0].shape[0]-1)\n",
    "    NUM = 24\n",
    "    fig_path = './results/Unet/'\n",
    "    save_svg(np.expand_dims(pred_test_img[NUM],axis=0), 'Unet', 'pre', fig_path)\n",
    "    save_svg(np.expand_dims(o_test_img[NUM],axis=0), 'Unet', 'o', fig_path)\n",
    "    save_svg(np.expand_dims(w_test_img[NUM],axis=0), 'Unet', 'w', fig_path)\n",
    "    print('test saved at:', fig_path)\n",
    "    \n",
    "    psnr_value, ssim_value, rmse = metrics(rescale(pred_test_img), o_test_img)\n",
    "    print('test performance:', psnr_value.round(2), ssim_value.round(2), rmse.round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45bd382e-d114-4025-8c35-4ef50e39f996",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "2023-11-23 11:25:02.996485: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-23 11:25:03.625102: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30987 MB memory:  -> device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:89:00.0, compute capability: 7.0\n",
      "2023-11-23 11:25:05.662777: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2023-11-23 11:25:06.772875: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8201\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test saved at: ./results/Unet/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/li52/code/LM/m-rBCR/util/metrics.py:14: FutureWarning: `multichannel` is a deprecated argument name for `structural_similarity`. It will be removed in version 1.0. Please use `channel_axis` instead.\n",
      "  ssim_value = ssim(IMG1, IMG2, multichannel=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test performance: 20.36 0.76 0.1\n"
     ]
    }
   ],
   "source": [
    "test()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e02a722-e2c7-4946-b92e-92b8dae4add3",
   "metadata": {},
   "source": [
    "# DDPM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d5b47a9-677e-400c-a926-52b73adfa102",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/li52/.conda/envs/LM/lib/python3.7/site-packages/requests/__init__.py:104: RequestsDependencyWarning: urllib3 (1.26.9) or chardet (5.1.0)/charset_normalizer (2.0.4) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n",
      "/home/li52/.conda/envs/LM/lib/python3.7/site-packages/tensorflow_addons/utils/ensure_tf_install.py:67: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.7.0 and strictly below 2.10.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.6.2 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  UserWarning,\n"
     ]
    }
   ],
   "source": [
    "# test on different dataset\n",
    "import os \n",
    "import numpy as np\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import random\n",
    "from natsort import natsorted\n",
    "from tqdm import tqdm\n",
    "\n",
    "from util.utils import *\n",
    "from models.Unet import *\n",
    "from util.loss_func import *\n",
    "from util.metrics import *\n",
    "from util.data import *\n",
    "from models.ddpm import train_model\n",
    "from util.ddpm_utils import variance_schedule\n",
    "\n",
    "def ddpm_obtain_sr_img(fx, timesteps_test, p_model, SMOOTH=0.01):\n",
    "    pred_sr = np.random.normal(0, 1, fx.shape)\n",
    "    gamma_vec_test, alpha_vec_test = variance_schedule(timesteps_test, schedule_type='linear', min_beta=1e-4,\n",
    "                                                       max_beta=3e-2) \n",
    "    smooth_factor = SMOOTH\n",
    "    for t in tqdm(range(timesteps_test, 0, -1)):\n",
    "        z = np.random.normal(0, 1, fx.shape)\n",
    "        if t == 1:\n",
    "            z = 0\n",
    "        alpha_t = alpha_vec_test[t - 1]\n",
    "        gamma_t = gamma_vec_test[t - 1]\n",
    "        gamma_tm1 = gamma_vec_test[t - 2]\n",
    "        beta_t = 1 - alpha_t\n",
    "        gamma_t_inp = np.ones((fx.shape[0], 1)) * np.reshape(gamma_t, (1, 1))\n",
    "        pred_noise = p_model.predict([pred_sr, fx, gamma_t_inp], verbose=False)\n",
    "\n",
    "        alpha_factor = beta_t / np.sqrt(1 - gamma_t)\n",
    "        beta_factor = (1 - gamma_tm1) * beta_t / (1 - gamma_t)\n",
    "        pred_sr = 1 / np.sqrt(alpha_t) * (pred_sr - alpha_factor * pred_noise) + np.sqrt(\n",
    "            beta_t) * z - smooth_factor * np.sign(pred_sr) * np.sqrt(beta_t)\n",
    "\n",
    "    return pred_sr\n",
    "\n",
    "\n",
    "def test(path = './weights/ddpm/'):\n",
    "    timesteps_test = 200\n",
    "    lr = 1e-4\n",
    "    opt_m = tf.keras.optimizers.Adam(lr)\n",
    "\n",
    "    # gamma_vec_t, alpha_vec = variance_schedule(timesteps, schedule_type='cos')\n",
    "    p_model_eval, t_model_eval = train_model((128,128,1), 1)\n",
    "    t_model_eval.compile(loss='mse', optimizer=opt_m)  # 用于sinus embedding的    \n",
    "\n",
    "    t_model_eval.load_weights(path + 'model_best.h5') # for the tarining on imagenet\n",
    "    MODEL = p_model_eval\n",
    "\n",
    "    test_dir = './data/test/'\n",
    "    test_list = natsorted(os.listdir(test_dir))  \n",
    "\n",
    "    test_raw = np.load(test_dir + test_list[0])  # select testset [imn, bio, storm, w_c]\n",
    "    w_test_img, o_test_img = test_raw['w'], test_raw['gt']\n",
    "\n",
    "    pred_test_img = ddpm_obtain_sr_img((w_test_img-0.5)/0.5, timesteps_test, p_model_eval, 0.01)\n",
    "\n",
    "    # save a rnadom fig under path\n",
    "    # NUM = random.randint(0, pred_test_list[0].shape[0]-1)\n",
    "    NUM = 24\n",
    "    fig_path = './results/ddpm/'\n",
    "    save_svg(np.expand_dims(pred_test_img[NUM],axis=0), 'Unet', 'pre', fig_path)\n",
    "    save_svg(np.expand_dims(o_test_img[NUM],axis=0), 'Unet', 'o', fig_path)\n",
    "    save_svg(np.expand_dims(w_test_img[NUM],axis=0), 'Unet', 'w', fig_path)\n",
    "    print('test saved at:', fig_path)\n",
    "\n",
    "    psnr_value, ssim_value, rmse = metrics(rescale(pred_test_img), o_test_img)\n",
    "    print('test performance:', psnr_value.round(2), ssim_value.round(2), rmse.round(2))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c764dd4d-6102-48a3-b599-6a380d223aa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-23 11:45:19.972269: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-23 11:45:20.602196: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30987 MB memory:  -> device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:89:00.0, compute capability: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 8, 8, 1024)\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 128, 128, 1) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               [(None, 128, 128, 1) 0           input_1[0][0]                    \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 128, 128, 1) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model (Functional)              (None, 128, 128, 1)  23988353    lambda_1[0][0]                   \n",
      "                                                                 input_2[0][0]                    \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.subtract (TFOpLambda)   (None, 128, 128, 1)  0           model[0][0]                      \n",
      "                                                                 lambda_1[0][1]                   \n",
      "==================================================================================================\n",
      "Total params: 23,988,353\n",
      "Trainable params: 23,988,353\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/200 [00:00<?, ?it/s]2023-11-23 11:45:22.911672: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2023-11-23 11:45:24.114183: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8201\n",
      "100%|██████████| 200/200 [01:16<00:00,  2.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test saved at: ./results/ddpm/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/li52/code/LM/m-rBCR/util/metrics.py:14: FutureWarning: `multichannel` is a deprecated argument name for `structural_similarity`. It will be removed in version 1.0. Please use `channel_axis` instead.\n",
      "  ssim_value = ssim(IMG1, IMG2, multichannel=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test performance: 21.22 0.65 0.09\n"
     ]
    }
   ],
   "source": [
    "test()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e86bb7f-166c-4924-aef7-4fe581d00fb7",
   "metadata": {},
   "source": [
    "# RL "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "629a42b4-37f3-444a-9a94-bd5e148f10da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test on different dataset\n",
    "import os \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import random\n",
    "from natsort import natsorted\n",
    "from scipy.signal import convolve2d as conv2\n",
    "from skimage import color, data, restoration\n",
    "\n",
    "from util.utils import *\n",
    "from util.metrics import *\n",
    "from util.data import *\n",
    "\n",
    "def test():\n",
    "\n",
    "    test_dir = './data/test/'\n",
    "    test_list = natsorted(os.listdir(test_dir))  \n",
    "    \n",
    "    test_raw = np.load(test_dir + test_list[0])  # select testset [imn, bio, storm, w_c]\n",
    "    w_test_img, o_test_img, psf_test_img = test_raw['w'], test_raw['gt'], test_raw['psf']\n",
    "    \n",
    "    deconv_RL_test = []\n",
    "    for i in range(w_test_img.shape[0]):\n",
    "        RL_temp = restoration.richardson_lucy(w_test_img[i].squeeze(), psf_test_img[i].squeeze(), num_iter=30)\n",
    "        deconv_RL_test.append(RL_temp)\n",
    "\n",
    "    deconv_RL_test = np.expand_dims(rescale(np.asarray(deconv_RL_test)), axis=-1)\n",
    "    # print(deconv_RL_test.shape, w_test_img.shape)\n",
    "    \n",
    "    # save a rnadom fig under path\n",
    "    # NUM = random.randint(0, pred_test_list[0].shape[0]-1)\n",
    "    NUM = 24\n",
    "    fig_path = './results/RL/'\n",
    "    save_svg(np.expand_dims(deconv_RL_test[NUM],axis=0), 'RL', 'pre', fig_path)\n",
    "    save_svg(np.expand_dims(o_test_img[NUM],axis=0), 'RL', 'o', fig_path)\n",
    "    save_svg(np.expand_dims(w_test_img[NUM],axis=0), 'RL', 'w', fig_path)\n",
    "    print('test saved at:', fig_path)\n",
    "    \n",
    "    psnr_value, ssim_value, rmse = metrics(deconv_RL_test, o_test_img)\n",
    "    print('test performance:', psnr_value.round(2), ssim_value.round(2), rmse.round(2))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "978dd801-2e72-4b75-91d3-eefbe9376d53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test saved at: ./results/RL/\n",
      "test performance: 13.39 0.48 0.21\n"
     ]
    }
   ],
   "source": [
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f83a2f-f6ef-4853-9fe0-89dd48db5a1a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CONDA (LM)",
   "language": "python",
   "name": "n2v-conda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
